{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04786c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                         std=[0.2023, 0.1994, 0.2010])\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10(\n",
    "    root=\"../data\",\n",
    "    train=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = CIFAR10(\n",
    "    root=\"../data\",\n",
    "    train=False,\n",
    "    transform= transform\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "valid_size = len(train_dataset) - train_size\n",
    "train_dataset, valid_dataset = random_split(train_dataset, [train_size, valid_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, 32, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, 32, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2184a572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SimpleCNN(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=16, kernel_size=3, padding=1, stride=2), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=16, out_channels= 32, kernel_size=3 , padding=1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            # Block 2\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size= 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            # nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            # FC\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 4 * 4, 256), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=0.2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        preds = self.layers(X)\n",
    "        return preds\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5f50cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.1138532507896424 Validation Accuracy: 0.6046\n",
      "Epoch 0: avg_loss :1.4060361347198487, accuracy :0.492\n",
      "Final Precision: 0.48588529229164124\n",
      "Final Recall: 0.49191686511039734\n",
      "Validation Loss: 0.9558962268829345 Validation Accuracy: 0.6611\n",
      "Epoch 1: avg_loss :0.9967478182554245, accuracy :0.646125\n",
      "Final Precision: 0.6434494256973267\n",
      "Final Recall: 0.6460368037223816\n",
      "Validation Loss: 0.8907347256660462 Validation Accuracy: 0.6885\n",
      "Epoch 2: avg_loss :0.8186102046489716, accuracy :0.71195\n",
      "Final Precision: 0.7099288702011108\n",
      "Final Recall: 0.7118694186210632\n",
      "Validation Loss: 0.8594109941482544 Validation Accuracy: 0.699\n",
      "Epoch 3: avg_loss :0.6973984870672226, accuracy :0.75245\n",
      "Final Precision: 0.7510395646095276\n",
      "Final Recall: 0.7523576021194458\n",
      "Validation Loss: 0.8623089943885803 Validation Accuracy: 0.711\n",
      "Epoch 4: avg_loss :0.5841926406264305, accuracy :0.793125\n",
      "Final Precision: 0.79215407371521\n",
      "Final Recall: 0.7930319905281067\n",
      "Validation Loss: 0.9418686904907226 Validation Accuracy: 0.7069\n",
      "Epoch 5: avg_loss :0.4913992434024811, accuracy :0.82635\n",
      "Final Precision: 0.8256615996360779\n",
      "Final Recall: 0.8262739181518555\n",
      "Validation Loss: 0.9666065100669861 Validation Accuracy: 0.7098\n",
      "Epoch 6: avg_loss :0.40475895245671273, accuracy :0.8536\n",
      "Final Precision: 0.8531206250190735\n",
      "Final Recall: 0.8535452485084534\n",
      "Validation Loss: 1.0535805688858033 Validation Accuracy: 0.701\n",
      "Epoch 7: avg_loss :0.33508494263589383, accuracy :0.878425\n",
      "Final Precision: 0.8781901001930237\n",
      "Final Recall: 0.8783693313598633\n"
     ]
    }
   ],
   "source": [
    "from  torch.optim import AdamW\n",
    "from torchmetrics import Precision, Recall\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN(3, 10)\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "precision = Precision(task=\"multiclass\", num_classes=10, average='macro').to(device)\n",
    "recall = Recall(task=\"multiclass\", num_classes=10, average='macro').to(device)\n",
    "\n",
    "model.train()\n",
    "def train(model, dataloader, loss_fn, optimizer):\n",
    "    expected_loss, samples, num_correct = 0,0,0\n",
    "\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = model(X)\n",
    "        loss = loss_fn(preds, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        samples += y.size(0)\n",
    "        expected_loss += loss.item() * y.size(0)\n",
    "\n",
    "        pred_classes = torch.argmax(preds, dim=1)\n",
    "        num_correct += (pred_classes == y).sum().item()\n",
    "\n",
    "        precision.update(pred_classes, y)\n",
    "        recall.update(pred_classes, y)\n",
    "        # if batch % 500 == 0:\n",
    "        #     print(f\"batch : {batch} loss: {expected_loss/ samples}\")\n",
    "\n",
    "    avg_loss = expected_loss/ samples\n",
    "    accuracy = num_correct / samples\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def validate(model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        num_correct = 0\n",
    "        num_samples = 0\n",
    "        for X,y in dataloader:\n",
    "            preds = model(X)\n",
    "            loss = loss_fn(preds, y)\n",
    "\n",
    "            num_samples += y.size(0)\n",
    "            total_loss += loss.item() * y.size(0)\n",
    "            pred_classes = torch.argmax(preds, dim=1)\n",
    "            num_correct += (pred_classes == y).sum().item()\n",
    "        print(f\"Validation Loss: {total_loss/num_samples} Validation Accuracy: {num_correct/num_samples}\")\n",
    "\n",
    "\n",
    "epochs= 10\n",
    "for i in range(epochs):\n",
    "    avg_loss, accuracy = train(model, train_dataloader, loss_fn, optimizer)\n",
    "    validate(model, valid_dataloader, loss_fn)\n",
    "    print(f\"Epoch {i}: avg_loss :{ avg_loss}, accuracy :{accuracy}\")\n",
    "\n",
    "    print(f\"Final Precision: {precision.compute()}\")\n",
    "    print(f\"Final Recall: {recall.compute()}\")\n",
    "    precision.reset()\n",
    "    recall.reset()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdfd617d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jtappen/.local/share/mamba/envs/ml/lib/python3.11/site-packages/torch/nn/functional.py:1538: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6388888955116272\n",
      "0.5925925970077515\n",
      "Loss : 0.9322456899166107, Accuracy : 0.7251\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    for X,y in test_dataloader:\n",
    "        preds = model(X)\n",
    "        loss = loss_fn(preds, y)\n",
    "\n",
    "        num_samples += y.size(0)\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        pred_classes = torch.argmax(preds, dim=1)\n",
    "        num_correct += (pred_classes == y).sum().item()\n",
    "\n",
    "    print(precision(pred_classes, y).item())\n",
    "    print(recall(pred_classes,y).item())\n",
    "    \n",
    "    print(f\"Loss : {total_loss/num_samples}, Accuracy : {num_correct/num_samples}\")\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5735f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"simple_cnn.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
